{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNdao159aIwrZQoslsyqNyP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"hSxBwYkuOc-E"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import pyarrow.parquet as pq\n","\n","trips = pq.read_table('trips.parquet') #to read parquet\n","\n","trips = trips.to_pandas() #converts to dataframe\n","zones = pd.read_csv('zones.csv') #the csv with the zones, converted to df"]},{"cell_type":"code","source":["tripsWithZones = pd.merge(trips,\n","                           zones,\n","                           left_on = 'PULocationID',\n","                           right_on = 'LocationID',\n","                           how = 'left')\n","\n","\n","finalTrips = tripsWithZones.drop('service_zone', axis = 1)\n","finalTrips = finalTrips.drop('hvfhs_license_num', axis = 1)\n","finalTrips = finalTrips.drop('dispatching_base_num', axis = 1)\n","finalTrips = finalTrips.drop('originating_base_num', axis = 1)\n","finalTrips = finalTrips.drop('request_datetime', axis = 1)\n","finalTrips = finalTrips.drop('on_scene_datetime', axis = 1)\n","finalTrips = finalTrips.drop('shared_request_flag', axis = 1)\n","finalTrips = finalTrips.drop('shared_match_flag', axis = 1)\n","finalTrips = finalTrips.drop('access_a_ride_flag', axis = 1)\n","finalTrips = finalTrips.drop('wav_request_flag', axis = 1)\n","finalTrips = finalTrips.drop('wav_match_flag', axis = 1)\n","\n","#modified table to get rid of unecessary columns"],"metadata":{"id":"IMSFajHJXVAK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#1) amount of trips by time interval (20 minutes)\n","\n","#group by 00 to 19, 20 to 39, 40 to 59\n","\n","#new columns for hours and minutes to group by them\n","\n","hoursList = []\n","minutesList = [] #1 signifies first third, 2 is second third, 3 is last third\n","\n","for time in finalTrips['pickup_datetime']:\n","  hoursList.append(time.time().hour)\n","  if time.time().minute in range(0,20):\n","    minutesList.append(1)\n","  elif time.time().minute in range(20,40):\n","    minutesList.append(2)\n","  else:\n","    minutesList.append(3)\n","\n","finalTrips['pickupHour'] = hoursList\n","finalTrips['pickupMinute'] = minutesList\n","\n","groupByTime = finalTrips.groupby(['pickupHour', 'pickupMinute'], as_index = False)\n","#within square brackets for group by multiple columns\n","\n","tripsByTime = groupByTime.size()\n","\n","print(tripsByTime.sort_values(by = 'size', ascending = False))"],"metadata":{"id":"BpbYdIWjiu7G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2) amount of trips by zone\n","\n","groupByZone = finalTrips.groupby('Zone', as_index = False)\n","\n","tripsByZone = groupByZone.size() #as_index = false above, then it returns dataframe\n","\n","print(tripsByZone.sort_values(by = 'size', ascending = False))\n","\n","#done - now going back to Boston data and creating a separate dataframe with\n","#3 columns: the amount of trips in the 20 min period, the amount of trips in\n","#the zone, and the weather at that time\n","\n","#then using those features to predict the surge multiplier with the\n","#machine learning model"],"metadata":{"id":"T2UmC4mEuWZX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#parquet to csv for swift\n","\n","import pandas as pd\n","import numpy as np\n","import pyarrow.parquet as pq\n","\n","trips = pq.read_table('trips.parquet') #to read parquet\n"],"metadata":{"id":"gONEsrkyrFVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tripsDf = trips.to_pandas()"],"metadata":{"id":"Mtg1eduh-aOK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tripsDf.to_csv('grandData.csv')"],"metadata":{"id":"UnqLDNnp-lRA"},"execution_count":null,"outputs":[]}]}